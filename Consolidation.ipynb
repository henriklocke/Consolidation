{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76f7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last updated: March 8, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca09eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import shutil\n",
    "import sqlite3\n",
    "import mikeio1d\n",
    "from mikeio1d.res1d import Res1D\n",
    "import ctypes\n",
    "MessageBox = ctypes.windll.user32.MessageBoxA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a128c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 2\n",
    "\n",
    "# user input\n",
    "skip_first_day = True #Must match system assessment import\n",
    "\n",
    "# #FSA vfd, 0\n",
    "# model_area = 'FSA'\n",
    "# map_folder=r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_0\\SA_Maps_V187_Ann0p8_0p3cms\"\n",
    "# model_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_0\\Model_V187_Ann0p8_0p3cms\"\n",
    "# model = \"FSA_2050pop_V187_BSF_14k_Sealed_VFD.sqlite\"\n",
    "# result_lookup_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_0\\HTML_Plots_V187_Ann0p8_0p3cms\"\n",
    "# ps_csv = 'PS_Capacity_FSA_2030_Network.csv'\n",
    "\n",
    "# #FSA vfd, 1A\n",
    "# model_area = 'FSA'\n",
    "# map_folder=r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\Maps_V187_Ann0p8_UpsNSIRX1p2m(A)_0p3cms\"\n",
    "# model_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\Model_V187_Ann0p8_UpsNSIRX1p2m(A)_0p3cms\"\n",
    "# model = \"FSA_2050pop_V187_BSF_14k_Sealed_VFD.sqlite\"\n",
    "# result_lookup_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\HTML_V187_Ann0p8_UpsNSIRX(A)_0p3cms\"\n",
    "# ps_csv = 'PS_Capacity_FSA_2030_Network.csv'\n",
    "\n",
    "\n",
    "# #FSA vfd, 1B\n",
    "# model_area = 'FSA'\n",
    "# map_folder=r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\Maps_V187_Ann0p8_UpsNSIRX2m(B)_0p3cms\"\n",
    "# model_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\Model_V187_Ann0p8_UpsNSIRX2m(B)_0p3cms\"\n",
    "# model = \"FSA_2050pop_V187_BSF_14k_Sealed_VFD.sqlite\"\n",
    "# result_lookup_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\HTML_V187_Ann0p8_UpsNSIRX2m(B)_0p3cms\"\n",
    "# ps_csv = 'PS_Capacity_FSA_2030_Network.csv'\n",
    "\n",
    "\n",
    "#FSA vfd, 1C\n",
    "model_area = 'FSA'\n",
    "map_folder=r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\Maps_V187_Ann0p8_UpsNSR(C)_0p3cms\"\n",
    "model_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\Model_V187_Ann0p8_UpsNSR(C)_0p3cms\"\n",
    "model = \"FSA_2050pop_V187_BSF_14k_Sealed_VFD.sqlite\"\n",
    "result_lookup_folder = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\HTML_V187_Ann0p8_UpsNSR(C)_0p3cms\"\n",
    "ps_csv = 'PS_Capacity_FSA_2030_Network.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3d68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 3\n",
    "\n",
    "try:\n",
    "\n",
    "    # import model data\n",
    "    # sql function\n",
    "    def sql_to_df(sql,model):\n",
    "      con = sqlite3.connect(model)\n",
    "      df = pd.read_sql(sql, con)\n",
    "      con.close()\n",
    "      return df\n",
    "\n",
    "\n",
    "    model_path = model_folder + '\\\\' + model\n",
    "\n",
    "    if not (model.lower().endswith('.sqlite') or model.lower().endswith('.mdb')):\n",
    "        raise ValueError(\"The variable 'model' must have .mdb or .sqlite extension: \" + model)\n",
    "    if os.path.exists(model_path) == False:\n",
    "        raise ValueError(\"The variable 'model' points to a path that does not exist: \" + model)    \n",
    "\n",
    "    sql = \"SELECT msm_Pump.AssetName, msm_Link.MUID \"\n",
    "    sql += \"FROM (msm_Pump INNER JOIN msm_Node ON msm_Pump.fromnodeid = msm_Node.MUID) \"\n",
    "    sql += \"INNER JOIN msm_Link ON msm_Node.MUID = msm_Link.tonodeid \"\n",
    "    sql += \"WHERE msm_Pump.active = 1 AND msm_Pump.enabled = 1 AND msm_Link.active = 1 \"\n",
    "    sql += \"GROUP BY msm_Pump.AssetName, msm_Node.MUID, msm_Link.MUID \"\n",
    "\n",
    "    pump_inflow_pipe_df = sql_to_df(sql,model_path)\n",
    "    pump_inflow_pipe_df\n",
    "\n",
    "    sql = \"SELECT AssetName, MUID \"\n",
    "    sql += \"FROM msm_Pump WHERE active = 1 AND msm_Pump.enabled = 1\"\n",
    "\n",
    "    pump_outflow_df = sql_to_df(sql,model_path)\n",
    "    \n",
    "except Exception as e:    \n",
    "    error_message = str(e)\n",
    "    MessageBox(None, b'An error happened in permanent cell 3\\n\\n' + error_message.encode('utf-8'), b\"Error\", 0)\n",
    "    raise ValueError(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea5f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 4\n",
    "\n",
    "# creating dictionaries\n",
    "\n",
    "try:\n",
    "\n",
    "    manual_adjusts = []\n",
    "    manual_adjusts.append(['28k','28p0k'])\n",
    "    manual_adjusts.append(['14k','14p0k'])\n",
    "\n",
    "    #Import variable from System_Assessment_Consolidation_Variables.py\n",
    "    sys.path.append(map_folder)\n",
    "    from System_Assessment_Consolidation_Variables import consolidationRanks\n",
    "    sys.path.remove(map_folder)\n",
    "    ps_dict={}\n",
    "    for consolidationRank in consolidationRanks:\n",
    "        ps_dict[consolidationRank[0]] = consolidationRank[1].lower()\n",
    "\n",
    "    color_dict={}\n",
    "    color_dict['green'] = ['lightgreen','black']\n",
    "    color_dict['blue'] = ['aqua','black']\n",
    "    color_dict['rm-blue'] = ['lightgreen','black']\n",
    "    color_dict['red'] = ['red','black']\n",
    "    color_dict['rm-red'] = ['red','black']\n",
    "    color_dict['purple'] = ['blueviolet','white']\n",
    "    color_dict['yellow'] = ['gold','black']\n",
    "    color_dict['orange'] = ['darkorange','black']\n",
    "    color_dict['darkred'] = ['darkred','white']\n",
    "    color_dict['black'] = ['black','white']\n",
    "\n",
    "    color_dict_ps = {}\n",
    "    color_dict_ps['green'] = ['lightgreen','black']\n",
    "    color_dict_ps['red'] = ['darkred','white']\n",
    "    color_dict_ps['black'] = ['black','white']\n",
    "\n",
    "    consolidation_acronym = pd.read_csv(map_folder+\"\\\\Consolidation_By_Acronym.csv\")\n",
    "    consolidation_acronym[\"Tab_ID\"] = consolidation_acronym.acronym\n",
    "\n",
    "    consolidation_by_pipe = pd.read_csv(map_folder+\"\\\\Consolidation_By_Pipes.csv\")\n",
    "    consolidation_events = pd.read_csv(map_folder + \"\\\\Consolidation_Events.csv\",dtype={'simyear': float,'msm_node_muid': str,'msm_link_muid': str},low_memory=False)\n",
    "    consolidation_events.dropna(subset=['consolidation_group'], inplace=True)\n",
    "    consolidation_events['simyear'] = consolidation_events['simyear'].astype(int)\n",
    "    consolidation_events[\"Pipe_Key\"]= consolidation_events.consolidation_group.astype(str) + \"-\" + consolidation_events.msm_link_muid.astype(str) +\"-\" + consolidation_events.simyear.astype(str)\n",
    "    consolidation_events.set_index([\"Pipe_Key\"],inplace=True)\n",
    "    consolidation_ps = pd.read_csv(map_folder+\"\\\\PS_Consolidation.csv\").dropna()\n",
    "    results = list(consolidation_events.result.unique())\n",
    "\n",
    "    ps_stats = pd.read_csv(map_folder + \"\\\\PS_Stats.csv\")\n",
    "    ps_stats = ps_stats[ps_stats['ResultFile'].isin(results)]\n",
    "\n",
    "    # ps_stats['Consolidation_Group'] = ps_stats['ResultFile'].astype(str).str[:-45]\n",
    "    if len(list(consolidation_by_pipe.consolidation_group.unique())) == 1:\n",
    "        consolidation_ps['Consolidation_Group'] = consolidation_by_pipe.consolidation_group.unique()[0]\n",
    "        ps_stats['Consolidation_Group'] = consolidation_by_pipe.consolidation_group.unique()[0]\n",
    "    else:\n",
    "        consolidation_ps['Consolidation_Group'] = consolidation_ps['map'].astype(str).apply(lambda x: re.search(r'(.*?\\d+k)', x).group(1) if re.search(r'(.*?\\d+k)', x) else None)\n",
    "        consolidation_ps.dropna(inplace=True)    \n",
    "        ps_stats['Consolidation_Group'] = ps_stats['ResultFile'].str.extract(r'^(.*?)(?=\\d{4}p)')\n",
    "        ps_stats['Consolidation_Group'] = ps_stats['Consolidation_Group'].str[:-1]\n",
    "        for manual_adjust in manual_adjusts:\n",
    "            consolidation_ps['Consolidation_Group'] = consolidation_ps['Consolidation_Group'].str.replace(manual_adjust[0], manual_adjust[1])\n",
    "            ps_stats['Consolidation_Group'] = ps_stats['Consolidation_Group'].str.replace(manual_adjust[0], manual_adjust[1])\n",
    "\n",
    "\n",
    "    ps_stats['Year'] = ps_stats['ResultFile'].str.extract(r'(\\d{4})p')\n",
    "    ps_stats['Year'] = ps_stats['Year'].astype(int)\n",
    "\n",
    "    ps_results = ps_stats[['ResultFile','Year','Consolidation_Group']].groupby(['ResultFile','Year','Consolidation_Group']).sum()\n",
    "    ps_results.reset_index(inplace=True)\n",
    "    ps_results.set_index(['ResultFile'],inplace=True)\n",
    "    \n",
    "except Exception as e:    \n",
    "    error_message = str(e)\n",
    "    MessageBox(None, b'An error happened in permanent cell 4\\n\\n' + error_message.encode('utf-8'), b\"Error\", 0)\n",
    "    raise ValueError(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfe103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\EFLSP_Modelling\\Phase_1\\Model_V187_Ann0p8_UpsNSR(C)_0p3cms\\FSA_2030pop_V187_BSF_16p8k_Sealed_VFD_m1d - Result Files\\FSA_BSF_16p8k_2030pop_S_V_2030_NetworkDefault_Network_HD.res1d\n",
      "Importing FSA_BSF_16p8k_2030pop_S_V_2030_NetworkDefault_Network_HD.res1d\n"
     ]
    }
   ],
   "source": [
    "#Permanent cell 5\n",
    "\n",
    "# import results\n",
    "try:\n",
    "\n",
    "    first_flow = True\n",
    "    for result in list(consolidation_events.result.unique()):\n",
    "        result_found = False\n",
    "        for f in os.listdir(model_folder):\n",
    "            if f[-7:] == '.sqlite':\n",
    "                result_subfolder = os.path.basename(f)[:-7] + '_m1d - Result Files'\n",
    "                try:\n",
    "                    for f1 in os.listdir(model_folder + '\\\\' + result_subfolder):\n",
    "                        if f1.lower() == result.lower():\n",
    "                            result_found = True\n",
    "                            result_path = model_folder + '\\\\' + result_subfolder + '\\\\' + f1\n",
    "                            print(result_path)\n",
    "                except:\n",
    "                    pass\n",
    "        if not result_found:\n",
    "            raise ValueError(\"Result file '\" + result + \"' not found.\")\n",
    "\n",
    "        print('Importing ' + result)\n",
    "        res1d = Res1D(result_path)\n",
    "        \n",
    "        timestep_seconds = (max(res1d.time_index) - min(res1d.time_index)).total_seconds() / (len(res1d.time_index)-1) \n",
    "        skip_steps = int(86400 / timestep_seconds) if skip_first_day else 0\n",
    "\n",
    "    #     for index, row in pump_inflow_pipe_df.iterrows():\n",
    "        for index, row in pump_outflow_df.iterrows():\n",
    "            muid = row['muid']\n",
    "            ps = row['assetname']\n",
    "            if ps in list(ps_stats.PS.unique()):\n",
    "                values = list(res1d.query.GetReachEndValues('Pump:' + muid, 'Discharge'))[skip_steps:]\n",
    "                flow_df = pd.DataFrame(index = res1d.time_index[skip_steps:])\n",
    "                flow_df['PS'] = ps\n",
    "                flow_df['Year'] = ps_results.loc[result,'Year']\n",
    "                flow_df['Consolidation_Group'] = ps_results.loc[result,'Consolidation_Group']\n",
    "                flow_df['MUID'] = muid\n",
    "                flow_df['DateTimeRef'] = flow_df.index\n",
    "                flow_df['Discharge'] = values\n",
    "\n",
    "                if first_flow == True:\n",
    "                    flow_df_all = flow_df.copy()\n",
    "                else:\n",
    "                    flow_df_all = pd.concat([flow_df_all,flow_df])\n",
    "                first_flow = False\n",
    "\n",
    "    flow_df_all\n",
    "\n",
    "    flow_df_ps = flow_df_all.groupby(['PS', 'Year', 'Consolidation_Group', 'DateTimeRef']).sum()\n",
    "    flow_df_ps.reset_index(inplace=True)\n",
    "    flow_df_ps.Discharge = flow_df_ps.Discharge*1000\n",
    "    time_bookends = [min(flow_df_ps.DateTimeRef),max(flow_df_ps.DateTimeRef)]\n",
    "\n",
    "except Exception as e:    \n",
    "    error_message = str(e)\n",
    "    MessageBox(None, b'An error happened in permanent cell 5\\n\\n' + error_message.encode('utf-8'), b\"Error\", 0)\n",
    "    raise ValueError(\"Error\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0dd73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 6\n",
    "\n",
    "try:\n",
    "    #Make PS htmls\n",
    "    years = list(consolidation_events.simyear.unique())\n",
    "    max_sim_year = max(years)\n",
    "    max_first_year = max(list(consolidation_acronym.firstyear.unique()))\n",
    "\n",
    "    html_path = map_folder + '\\\\Acronym_Summary'\n",
    "    try:\n",
    "        os.makedirs(html_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    shutil.copy2('style.css', html_path + '\\\\style.css')\n",
    "    shutil.copy2('script.js', html_path + '\\\\script.js')\n",
    "\n",
    "    for consolidation_group in list(consolidation_ps.Consolidation_Group.unique()):\n",
    "        print('Creating html for ' + consolidation_group)\n",
    "        consolidation_group_df = consolidation_ps[consolidation_ps.Consolidation_Group == consolidation_group]\n",
    "\n",
    "        f = open(html_path + '\\\\'+ consolidation_group + '_PS.html', \"w\")\n",
    "        f.write('<link rel=\"stylesheet\" href=\"style.css\">\\n')\n",
    "        f.write('<script src=\"script.js\"></script>\\n')\n",
    "        f.write('<link rel=\"stylesheet\" href=\"style.css\">\\n')\n",
    "        f.write('<!DOCTYPE html>\\n')\n",
    "        f.write('<html>\\n')\n",
    "        f.write('<head>\\n')\n",
    "        f.write('<meta charset=\"utf-8\">\\n')\n",
    "        f.write('</head>\\n')\n",
    "        f.write('<body>\\n\\n')\n",
    "\n",
    "        f.write('<div class=\"tab\">\\n')\n",
    "        for index, row in consolidation_group_df.iterrows():\n",
    "            tab = row[\"ps\"] \n",
    "            first_year = row['firstyear']\n",
    "            color = ps_dict[first_year]\n",
    "\n",
    "            bg_color = color_dict[color][0]\n",
    "            text_color = color_dict[color][1]\n",
    "\n",
    "            f.write('  <button class=\"tablinks\" onclick=\"openTab(event, ' + \"'\" + tab + \"'\"  \n",
    "                    + ')\" style=\"background-color:' + bg_color + '; color:' + text_color + ';\">' + tab + '</button>\\n')\n",
    "        f.write('</div>\\n')\n",
    "\n",
    "        for index, row in consolidation_group_df.iterrows():\n",
    "            ps = row[\"ps\"]\n",
    "            tab = ps\n",
    "            f.write('<div id=\"' + tab + '\" class=\"tabcontent\">\\n')  \n",
    "            f.write('<h1>' + ps + '</h1>')\n",
    "\n",
    "\n",
    "            f.write('<div class=\"row\"><div class=\"column\">\\n') \n",
    "\n",
    "    #         PS INDEX\n",
    "\n",
    "            f.write('<table style=\\'width: 60%;\\'>\\n')\n",
    "            f.write('<tr>\\n')\n",
    "            f.write('<th>Legend</th>\\n')\n",
    "            f.write('</tr>\\n')\n",
    "            f.write('\\n')\n",
    "            f.write('<tr><td style=\"background-color: black; color:white\">> Station capacity </td></tr>\\n')\n",
    "            f.write('<tr><td style=\"background-color: darkred; color:white\">> Firm capacity </td></tr>\\n')\n",
    "            f.write('<tr><td style=\"background-color: lightgreen; color:black\"> < Firm capacity </td></tr>\\n')     \n",
    "            f.write('</table>\\n')\n",
    "            f.write('<br>\\n')\n",
    "\n",
    "\n",
    "\n",
    "    #         PS table\n",
    "\n",
    "\n",
    "            f.write('<table style=\\'width: 50%;\\'>\\n')\n",
    "            f.write('<tr>\\n')\n",
    "            f.write('<th rowspan=\"2\">Year</th>\\n') \n",
    "\n",
    "            f.write('<th>PS Outflow</th>\\n') \n",
    "            f.write('<th>Firm Capacity</th>\\n') \n",
    "            f.write('<th>Station Capacity</th>\\n') \n",
    "            f.write('</tr>\\n')\n",
    "            f.write('<th colspan=\"3\" style=\"text-align: center\">Discharge (L/s)</th>\\n')    \n",
    "            f.write('<tr>\\n')\n",
    "\n",
    "\n",
    "\n",
    "            for i,year in enumerate(years):\n",
    "\n",
    "                ps_stats_row = ps_stats[(ps_stats.Year == year)&(ps_stats.Consolidation_Group == consolidation_group)&(ps_stats.PS == ps)].copy()\n",
    "                ps_stats_row.reset_index(inplace = True)\n",
    "                discharge = round(ps_stats_row.loc[0,'MaxTotalOutflow'],1)\n",
    "                firm_capacity = round(ps_stats_row.loc[0,'FirmCapacity'],0)\n",
    "                station_capacity = round(ps_stats_row.loc[0,'StationCapacity'],0)\n",
    "                color = ps_stats_row.loc[0,'Color'].lower()\n",
    "\n",
    "                if color == 'red':\n",
    "                    color = 'darkred'\n",
    "\n",
    "                bg_color = color_dict[color][0]\n",
    "                text_color = color_dict[color][1]\n",
    "\n",
    "\n",
    "                f.write('<tr>\\n')\n",
    "\n",
    "\n",
    "\n",
    "                f.write('<td>'+ str(year) + '</td>\\n')\n",
    "\n",
    "                f.write('<td style=\"background-color:'+ bg_color + '; color:' + text_color + ';\">' + str(discharge)+'</td>\\n')\n",
    "                if i == 0:\n",
    "                    f.write('<td rowspan=\"' + str(len(years)) + '\" style=\"text-align: center\">' + str(firm_capacity) + '</td>\\n')    \n",
    "                    f.write('<td rowspan=\"' + str(len(years)) + '\"style=\"text-align: center\">' + str(station_capacity) + '</td>\\n')\n",
    "\n",
    "                f.write('</tr>\\n')\n",
    "            f.write('</table>\\n')\n",
    "\n",
    "\n",
    "            f.write('</div>\\n')             \n",
    "            f.write('<div class=\"column\">\\n')\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            firm_capacity = ps_stats[ps_stats.PS==ps].iloc[0,4]\n",
    "            station_capacity = ps_stats[ps_stats.PS==ps].iloc[0,5]\n",
    "\n",
    "            fig.add_trace(go.Scatter(x=time_bookends, \n",
    "                                     y = [station_capacity,station_capacity], \n",
    "                                     mode='lines',line_color='black',name='Station Capacity')) \n",
    "\n",
    "            fig.add_trace(go.Scatter(x=time_bookends, \n",
    "                                     y = [firm_capacity,firm_capacity], \n",
    "                                     mode='lines',line_color='red',name='Firm Capacity'))   \n",
    "\n",
    "            for year in years:\n",
    "                flow_df_ps_single = flow_df_ps[(flow_df_ps.PS==ps) & (flow_df_ps.Consolidation_Group==consolidation_group)\n",
    "                                              & (flow_df_ps.Year==year)]\n",
    "                fig.add_trace(go.Scatter(x = flow_df_ps_single.DateTimeRef, \n",
    "                                         y = flow_df_ps_single.Discharge,name=str(year)))\n",
    "            fig.update_layout(\n",
    "            title='Inflow to ' + ps,\n",
    "            autosize=False,\n",
    "            width = 1000,\n",
    "            height=600,\n",
    "            margin=dict(\n",
    "                l=50,\n",
    "                r=50,\n",
    "                b=50,\n",
    "                t=50,\n",
    "                pad=4\n",
    "                ),\n",
    "                yaxis_title = 'Discharge (L/s)'\n",
    "            )\n",
    "\n",
    "\n",
    "            f.write(fig.to_html(full_html=False, include_plotlyjs='cdn'))      \n",
    "\n",
    "            f.write('</div>\\n')\n",
    "            f.write('</div>\\n')  \n",
    "            f.write(\"</div>\\n\")\n",
    "\n",
    "        f.write('</body>\\n')\n",
    "        f.write('</html>\\n')\n",
    "        f.close()\n",
    "\n",
    "    print(\"Finished\")\n",
    "\n",
    "except Exception as e:    \n",
    "    error_message = str(e)\n",
    "    MessageBox(None, b'An error happened in permanent cell 6\\n\\n' + error_message.encode('utf-8'), b\"Error\", 0)\n",
    "    raise ValueError(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 7\n",
    "\n",
    "try:\n",
    "    # create acronym HTML\n",
    "    years = list(consolidation_events.simyear.unique())\n",
    "    max_sim_year = max(years)\n",
    "    max_first_year = max(list(consolidation_acronym.firstyear.unique()))\n",
    "\n",
    "    html_path = map_folder + '\\\\Acronym_Summary'\n",
    "    if not os.path.exists(html_path):\n",
    "        os.makedirs(html_path)\n",
    "\n",
    "    shutil.copy2('style.css', html_path + '\\\\style.css')\n",
    "    shutil.copy2('script.js', html_path + '\\\\script.js')\n",
    "\n",
    "    for consolidation_group in list(consolidation_acronym.consolidation_group.unique()):\n",
    "        consolidation_group_df = consolidation_acronym[consolidation_acronym.consolidation_group == consolidation_group]\n",
    "\n",
    "        f = open(html_path + '\\\\'+ consolidation_group + '.html', \"w\")\n",
    "        f.write('<link rel=\"stylesheet\" href=\"style.css\">\\n')\n",
    "        f.write('<script src=\"script.js\"></script>\\n')\n",
    "        f.write('<link rel=\"stylesheet\" href=\"style.css\">\\n')\n",
    "        f.write('<!DOCTYPE html>\\n')\n",
    "        f.write('<html>\\n')\n",
    "        f.write('<head>\\n')\n",
    "        f.write('<meta charset=\"utf-8\">\\n')\n",
    "        f.write('</head>\\n')\n",
    "        f.write('<body>\\n\\n')\n",
    "\n",
    "        f.write('<div class=\"tab\">\\n')\n",
    "        for index, row in consolidation_group_df.iterrows():\n",
    "            tab = row[\"Tab_ID\"] + '(G)' if row[\"pmapprno\"]==0 else row[\"Tab_ID\"] + '(F)'\n",
    "            color=row[\"consolidation_color\"]\n",
    "            color = color[3:].lower()\n",
    "            bg_color = color_dict[color][0]\n",
    "            text_color = color_dict[color][1]\n",
    "            if color == \"green\": \n",
    "                color = \"lightgreen\"\n",
    "            f.write('  <button class=\"tablinks\" onclick=\"openTab(event, ' + \"'\" + tab + \"'\"  \n",
    "                    + ')\" style=\"background-color:' + bg_color + '; color:' + text_color + ';\">' + tab + '</button>\\n')\n",
    "        f.write('</div>\\n')\n",
    "\n",
    "\n",
    "        previous_tab = 'placeholder'\n",
    "        for index, row in consolidation_group_df.iterrows():\n",
    "            acronym = row[\"acronym\"]\n",
    "            tab = row[\"Tab_ID\"] + '(G)' if row[\"pmapprno\"]==0 else row[\"Tab_ID\"] + '(F)'\n",
    "\n",
    "\n",
    "            previous_tab = tab\n",
    "        #     if ps == 'Katzie PS':\n",
    "            if 1 == 1:\n",
    "\n",
    "        #         if i == -1: #Make tab active ----This gives wrong zoom levels so it is temporarily disabled until fixed\n",
    "        #             f.write('<div id=\"' + tab + '\" class=\"tabcontent\" style=\"display:block\">\\n')\n",
    "        #         else:\n",
    "                f.write('<div id=\"' + tab + '\" class=\"tabcontent\">\\n')    \n",
    "\n",
    "                header_text = \"Gravity Main \" + acronym if row[\"pmapprno\"]==0 else \"Force Main \" + acronym\n",
    "    #             f.write(\"<h1>\" + header_text</h1>\\n\") \n",
    "                f.write(\"<h2>\" + header_text + \"</h2>\\n\") \n",
    "\n",
    "                exceedance_text = str(row['firstyear']) if max_first_year>row['firstyear'] else 'beyond ' + str(max_sim_year)\n",
    "                exceedance_text = \"First exceedance: \" + exceedance_text\n",
    "                f.write(\"<p>\" + exceedance_text + \"</p>\\n\") \n",
    "\n",
    "                pm_no = row[\"pmapprno\"]\n",
    "\n",
    "                acronym_pipes = consolidation_by_pipe.loc[(consolidation_by_pipe.consolidation_group == consolidation_group) &(consolidation_by_pipe.acronym == acronym) & (consolidation_by_pipe.pmapprno == pm_no)]\n",
    "    #             details_events = consolidation_events.loc[(consolidation_events.Consolidation_Group == consolidation_group) & (consolidation_events.SimYear == simyear) & (consolidation_events.Max_V == max_v) & (consolidation_events.Max_WL_Above_SOH == max_WL_above_SOH)\n",
    "    #                                                        & (consolidation_events.Color == color) & (consolidation_events.PmApprNo == pm_no)]\n",
    "\n",
    "    #             f.write('<div class=\"row\"><div class=\"column\">\\n')\n",
    "                f.write('<div class=\"sidenav\">\\n')\n",
    "\n",
    "                path = result_lookup_folder + r\"\\All_Longsections\\Long_Section_\" + acronym + \".html\"\n",
    "\n",
    "                f.write('<p><a href=\"' + path + '\" target=\"_blank\">Open Long Section</a></p>\\n')\n",
    "\n",
    "                       ################ Index \n",
    "                if pm_no == 0:\n",
    "    #                \n",
    "\n",
    "                    f.write('<table style=\\'width: 40%;\\'>\\n')\n",
    "                    f.write('<tr>\\n')\n",
    "                    f.write('<th>Legend</th>\\n')\n",
    "                    f.write('</tr>\\n')\n",
    "                    f.write('\\n')\n",
    "                    f.write('<tr><td style=\"background-color: black; color:white\"> WL > GL and SOH </td></tr>\\n')\n",
    "                    f.write('<tr><td style=\"background-color: red; color:black\"> WL < GL and > SOH </td></tr>\\n')\n",
    "    #                 f.write('<tr><td style=\"background-color: aqua; color:black\"> WL +/- 5cm of SOH </td></tr>\\n')\n",
    "                    f.write('<tr><td style=\"background-color: blueviolet; color:white\"> WL > GL and < SOH </td></tr>\\n')\n",
    "                    f.write('<tr><td style=\"background-color: gold; color:black\"> WL > crown and < GL and < SOH </td></tr>\\n')\n",
    "                    f.write('<tr><td style=\"background-color: lightgreen; color:black\"> WL < SOH and crown </td></tr>\\n')\n",
    "\n",
    "                    f.write('</table>\\n')\n",
    "\n",
    "                else:\n",
    "                    f.write('<table>\\n')\n",
    "                    f.write('<tr>\\n')\n",
    "                    f.write('<th>Legend</th>\\n')\n",
    "                    f.write('</tr>\\n')\n",
    "                    f.write('\\n')\n",
    "                    f.write('<tr><td style=\"background-color: red; color:black\"> velocity >= 3 m/s </td></tr>\\n')          \n",
    "                    f.write('<tr><td style=\"background-color: lightgreen; color:black\"> velocity < 3 m/s </td></tr>\\n')\n",
    "                    f.write('</table>\\n')\n",
    "\n",
    "             ################ Index  \n",
    "                f.write('<br>\\n')\n",
    "\n",
    "                f.write('<table style=\\'width: 50%;\\'>\\n')\n",
    "                f.write('<tr>\\n')\n",
    "                f.write('<th rowspan=\"2\">Pipe</th>\\n') \n",
    "\n",
    "                f.write('<th rowspan=\"2\">Node MUID</th>\\n') \n",
    "                f.write('<th rowspan=\"2\">Node Name</th>\\n') \n",
    "\n",
    "                f.write('<th rowspan=\"2\">Year Exceeded</th>\\n')\n",
    "                f.write('<th>Invert</th>\\n')\n",
    "                f.write('<th>Crown</th>\\n')\n",
    "                f.write('<th>SOH</th>\\n')\n",
    "                f.write('<th>Ground</th>\\n')\n",
    "    #    \n",
    "\n",
    "                for _ in range(2):\n",
    "                    for sim_year in years:\n",
    "                        f.write('<th>' + str(sim_year) + '</th>\\n')\n",
    "\n",
    "                f.write('</tr>\\n')\n",
    "\n",
    "                f.write('<tr>\\n')\n",
    "                f.write('<th colspan=\"4\" style=\"text-align: center\">Elevation (m)</th>\\n')\n",
    "                value_header = \"Max Water Level (m)\" if pm_no == 0 else \"Max Velocity (m/s)\"\n",
    "                value_cols = len(years)\n",
    "                f.write('<th colspan=\"' + str(value_cols) + '\">' + str(value_header) + '</th>\\n')\n",
    "                f.write('<th colspan=\"4\" style=\"text-align: center\">Max Discharge (L/s)</th>\\n')\n",
    "                f.write('</tr>\\n')\n",
    "\n",
    "\n",
    "\n",
    "                pm_no = row[\"pmapprno\"]\n",
    "\n",
    "                for index,row in acronym_pipes.iterrows():\n",
    "                    f.write('<tr>\\n')\n",
    "\n",
    "    #                 add hyperlink\n",
    "\n",
    "\n",
    "                    pipe = row['msm_link_muid']\n",
    "\n",
    "                    path = result_lookup_folder + '\\\\All_Elements\\\\' + model_area + '_Discharge_Link_' + pipe + '.html'\n",
    "\n",
    "                    f.write('<td><a href=\"' + path + '\" target=\"_blank\">'+ pipe + '</a></td>\\n')\n",
    "\n",
    "\n",
    "\n",
    "                    color=row[\"consolidation_color\"]\n",
    "                    color = color[3:].lower()\n",
    "                    bg_color = color_dict[color][0]\n",
    "                    text_color = color_dict[color][1]\n",
    "\n",
    "    #                 </a>\n",
    "\n",
    "                    pipe_key = consolidation_group + \"-\" + pipe + \"-\" + str(years[0])\n",
    "\n",
    "    #                  add hyperlink \n",
    "\n",
    "                    node = consolidation_events.loc[pipe_key,'msm_node_muid']           \n",
    "                    path = result_lookup_folder + '\\\\All_Elements\\\\' + model_area + '_WaterLevel_Node_' + node + '.html'\n",
    "\n",
    "                    f.write('<td><a href=\"' + path + '\" target=\"_blank\">'+ node + '</a></td>\\n')\n",
    "\n",
    "\n",
    "                    assetname = str(consolidation_events.loc[pipe_key,'assetname'])\n",
    "                    assetname = \"\" if assetname == 'nan' else assetname\n",
    "                    f.write('<td>'+ assetname + '</td>\\n')\n",
    "\n",
    "                    first_year = row['firstyear'] if max_first_year>row['firstyear'] else '> ' + str(max_sim_year)\n",
    "                    f.write('<td style=\"background-color:'+ bg_color + '; color:' + text_color + ';\">' + str(first_year) + '</td>\\n')\n",
    "\n",
    "\n",
    "                    f.write('<td>'+ str(round(consolidation_events.loc[pipe_key,'invertlevel'],2)) + '</td>\\n')\n",
    "                    f.write('<td>'+ str(round(consolidation_events.loc[pipe_key,'pipecrown'],2)) + '</td>\\n')\n",
    "\n",
    "                    soh = consolidation_events.loc[pipe_key,'criticallevel']\n",
    "                    soh = round(soh,2) if not np.isnan(soh) else ''\n",
    "                    f.write('<td>'+ str(soh) + '</td>\\n')\n",
    "                    f.write('<td>'+ str(round(consolidation_events.loc[pipe_key,'groundlevel'],2)) + '</td>\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    for sim_year in years:\n",
    "                        pipe_key = consolidation_group + \"-\" + pipe + \"-\" + str(sim_year)\n",
    "                        try:\n",
    "                            color = consolidation_events.loc[pipe_key,\"color\"].lower()\n",
    "                            bg_color = color_dict[color][0]\n",
    "                            text_color = color_dict[color][1]\n",
    "\n",
    "\n",
    "\n",
    "                            if pm_no == 0:\n",
    "                                value = consolidation_events.loc[pipe_key,\"maxwl\"]\n",
    "                            else:\n",
    "                                value = consolidation_events.loc[pipe_key,\"maxv\"]\n",
    "                            if type(value) == np.nan:\n",
    "                                value = \"\"\n",
    "                            else:\n",
    "                                value = round(value,2)\n",
    "\n",
    "\n",
    "                            f.write('<td style=\"background-color:'+ bg_color + '; color:' + text_color + ';\">' + str(value)+'</td>\\n')\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    for sim_year in years:\n",
    "                        pipe_key = consolidation_group + \"-\" + pipe + \"-\" + str(sim_year)\n",
    "                        try:\n",
    "                            discharge_value = consolidation_events.loc[pipe_key,\"maxq\"]*1000\n",
    "                            f.write('<td>' + str(int(round(discharge_value, 0))) + '</td>\\n')\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    f.write('</tr>\\n')\n",
    "                f.write('</table>\\n')\n",
    "                for i in range(10):\n",
    "                    f.write('<h1 style=\"color: white\">End of tables</h1>\\n')#Invisible, just to enable scroll to table bottoms\n",
    "\n",
    "    #             <a href=\"\\\\prdsynfile01\\lws_modelling\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\X_Times_BSF\\HTML_Plots_V126\\All_Longsections\"acronym\"\" target=\"_blank\">Open Long Section</a>\n",
    "\n",
    "\n",
    "                f.write('</div>\\n')\n",
    "\n",
    "\n",
    "    #             f.write('<div class=\"column\">\\n')\n",
    "                f.write('<div class=\"main\">\\n')\n",
    "\n",
    "\n",
    "                if pm_no == 0:\n",
    "                    map = acronym + \"-GM-\" + consolidation_group\n",
    "                else:\n",
    "                    map = acronym + \"-FM-\" + consolidation_group\n",
    "                map_string = '<img src=\"Maps\\\\' + map + '.jpg\" alt=\"' + map + '\">\\n'\n",
    "                f.write(map_string + \"\\n\")\n",
    "                f.write('</div>\\n')    \n",
    "    #             f.write('</div>\\n')\n",
    "\n",
    "                f.write(\"</div>\\n\")  \n",
    "\n",
    "        f.write('</body>\\n')\n",
    "        f.write('</html>\\n')\n",
    "        f.close()\n",
    "\n",
    "    print(\"Finished\")\n",
    "    \n",
    "except Exception as e:    \n",
    "    error_message = str(e)\n",
    "    MessageBox(None, b'An error happened in permanent cell 7\\n\\n' + error_message.encode('utf-8'), b\"Error\", 0)\n",
    "    raise ValueError(\"Error\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37212110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_mike",
   "language": "python",
   "name": "py39_mike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
